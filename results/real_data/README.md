# Real-data HMM-MoA vs HMM-TinyRNN Results

This report mirrors the synthetic benchmarking summary for the Mixture-of-Agents style
behavioural sessions. The committed run was executed in demo mode inside this repository,
so the metrics reflect a surrogate long-dwell two-step generator; swapping in a converted
`.npz` bundle from the real dataset will populate the same structure with genuine results.

## Run configuration

- Command: `python -m series_hmm_rnn.run_real_data_pipeline --demo-synthetic --epochs 5 --out-dir results/real_data/demo --device cpu`
- Training epochs: 5 with Adam (lr = 1e-3)
- Hidden units: HMM-MoA = 6, HMM-TinyRNN = 6, phases `K = 2`, temperature `tau = 1.25`
- Hold-out split: 80% sessions train / 20% test (rounded to integers)
- Sticky initial transition prior: 0.97 self-transition probability

## Evaluation metrics

| Model              | Split | NLL  | Action accuracy | Phase accuracy |
|--------------------|-------|------|-----------------|----------------|
| HMM-MoA  | Train | 0.920 | 0.567           | 0.538          |
| HMM-MoA  | Test  | 0.909 | 0.575           | 0.635          |
| HMM-TinyRNN  | Train | 0.656 | 0.528           | 0.935          |
| HMM-TinyRNN  | Test  | 0.667 | 0.490           | 0.935          |

## Visual summaries

- [Training NLL](./demo_fig/real_demo_train_nll.svg) / [Training accuracy](./demo_fig/real_demo_train_accuracy.svg)
- [Evaluation accuracy (train/test)](./demo_fig/real_demo_action_accuracy.svg) / [Phase alignment](./demo_fig/real_demo_phase_accuracy.svg)
- [Mixture responsibilities](./demo_fig/real_demo_agent_mix_hmm_moa.svg) / [Phase responsibilities](./demo_fig/real_demo_agent_mix_hmm_tinyrnn.svg) and state posteriors for [HMM-MoA](./demo_fig/real_demo_state_posterior_hmm_moa.svg) / [HMM-TinyRNN](./demo_fig/real_demo_state_posterior_hmm_tinyrnn.svg)
- Trial-history panels normalised into the common/rare × reward/omission format:
  - [Observed behaviour](./demo_fig/real_demo_trial_history_observed.svg)
  - [HMM-MoA](./demo_fig/real_demo_trial_history_hmm_moa.svg)
  - [HMM-TinyRNN](./demo_fig/real_demo_trial_history_hmm_tinyrnn.svg)
  - [Canonical agents (MF reward/choice, model-based, bias)](./demo_fig/real_demo_trial_history_agent_mf_reward.svg) with matching `agent_*` companions

The trial-history panels fit logistic regressions that include reward, transition, and
reward×transition interaction terms. Coefficients are reported in the intuitive stay-bias
layout where each lag contributes weights for *common/rare* and *reward/omission* pairings,
mirroring the presentations used in the Mixture-of-Agents papers.

## Artefacts committed for reference

- [`demo/`](./demo/) stores `history.json`, `metrics.json`, `posterior_trace.json`, and `trial_history.json` for both models and agents.
- [`demo_fig/`](./demo_fig/) contains the SVG plots generated by
  `python scripts/plot_synthetic_results.py results/real_data/demo --out-dir results/real_data/demo_fig --prefix real_demo`.
- [`comparison.md`](./comparison.md) narrates the new HMM-MoA versus HMM-TinyRNN responsibility comparison figures.
- [`sample_trace.json`](./demo/sample_trace.json) captures a representative session (actions,
  rewards, transitions, phases) used when constructing the visualisations and logistic fits.

## Reproducing with your own dataset

1. Convert the MixtureAgentsModels MATLAB exports into a NumPy bundle as described in
   [`scripts/convert_mixture_agents.py`](../../scripts/convert_mixture_agents.py).
2. Run the pipeline, pointing `--data` to the converted `.npz` file and adjusting `--epochs`
   as needed. All logs and figures will appear under your chosen `--out-dir`.
3. Regenerate the figures (including the trial-history regressions) with
   `python scripts/plot_synthetic_results.py <out-dir> --out-dir fig --prefix <name>`.

Replace the demo artefacts in this folder with the outputs from the real dataset to keep
synthetic and empirical comparisons aligned.
