# Real-data HMM-MoA vs TinyRNN Results

This report mirrors the synthetic benchmarking summary for the Mixture-of-Agents style
behavioural sessions. The committed run was executed in demo mode inside this repository,
so the metrics reflect a surrogate long-dwell two-step generator; swapping in a converted
`.npz` bundle from the real dataset will populate the same structure with genuine results.

## Run configuration

- Command: `python -m series_hmm_rnn.run_real_data_pipeline --demo-synthetic --epochs 5 --out-dir results/real_data/demo --device cpu`
- Training epochs: 5 with Adam (lr = 1e-3)
- Hidden units: HMM-MoA = 6, HMM-TinyRNN = 6, phases `K = 2`, temperature `tau = 1.25`
- Hold-out split: 80% sessions train / 20% test (rounded to integers)
- Sticky initial transition prior: 0.97 self-transition probability

## Evaluation metrics

| Model       | Split | NLL  | Action accuracy | Phase accuracy |
|-------------|-------|------|-----------------|----------------|
| HMM-MoA     | Train | 0.920 | 0.567           | 0.538          |
| HMM-MoA     | Test  | 0.909 | 0.575           | 0.635          |
| HMM-TinyRNN | Train | 0.656 | 0.528           | 0.935          |
| HMM-TinyRNN | Test  | 0.667 | 0.490           | 0.935          |

## Visual summaries

- [Training NLL](./demo_fig/real_demo_train_nll.svg) / [Training accuracy](./demo_fig/real_demo_train_accuracy.svg)
- [Evaluation accuracy (train/test)](./demo_fig/real_demo_action_accuracy.svg) / [Phase alignment](./demo_fig/real_demo_phase_accuracy.svg)
- [Latent posterior traces](./demo_fig/real_demo_hmm_moa_posterior.svg) and [TinyRNN posterior](./demo_fig/real_demo_hmm_tinyrnn_posterior.svg)
- [HMM-MoA agent mixture weights](./demo_fig/real_demo_hmm_moa_agent_mixture.svg) showing the
  per-trial contribution of the **model-free value**, **model-free choice**, **model-based**, and
  **bias** components.
- [Trial-history regression (reward)](./demo_fig/real_demo_trial_history_reward.svg) /
  [choice](./demo_fig/real_demo_trial_history_choice.svg) /
  [choice Ã— reward interaction](./demo_fig/real_demo_trial_history_interaction.svg)

The trial-history curves fit a simple logistic regression on sequences sampled from each
model (arg-max policy) using the recorded rewards as proxies for outcomes, matching the
conventions in the HMM-MoA literature.

The HMM-MoA posterior JSON (`demo/hmm_moa/posterior_trace.json`) includes
`agent_mixture` weights with the corresponding agent labels so you can quantify the
relative contribution of the model-free (value and choice channels separately), model-based,
and bias components for each trial.

## Artefacts committed for reference

- [`demo/`](./demo/) stores `history.json`, `metrics.json`, and `posterior_trace.json` for both models.
- [`demo_fig/`](./demo_fig/) contains the SVG plots generated by
  `python scripts/plot_synthetic_results.py results/real_data/demo --out-dir results/real_data/demo_fig --prefix real_demo`.
- [`sample_trace.json`](./demo/sample_trace.json) captures a representative session (actions,
  rewards, transitions, phases) used when constructing the visualisations and logistic fits.

## Reproducing with your own dataset

1. Convert the MixtureAgentsModels MATLAB exports into a NumPy bundle as described in
   [`scripts/convert_mixture_agents.py`](../../scripts/convert_mixture_agents.py).
2. Run the pipeline, pointing `--data` to the converted `.npz` file and adjusting `--epochs`
   as needed. All logs and figures will appear under your chosen `--out-dir`.
3. Regenerate the figures (including the trial-history regressions) with
   `python scripts/plot_synthetic_results.py <out-dir> --out-dir fig --prefix <name>`.

Replace the demo artefacts in this folder with the outputs from the real dataset to keep
synthetic and empirical comparisons aligned.
